{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/phamquiluan/PubLayNet/blob/master/maskrcnn/infer.py\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES2LABELS = {\n",
    "    0: \"bg\",\n",
    "    1: \"text\",\n",
    "    2: \"title\",\n",
    "    3: \"list\",\n",
    "    4: \"table\",\n",
    "    5: \"figure\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes)\n",
    "    \n",
    "    model.training = False\n",
    "    model.roi_heads.box_predictor.training = False\n",
    "    model.roi_heads.mask_predictor.conv5_mask.training = False\n",
    "    model.roi_heads.mask_predictor.training = False\n",
    "    return model\n",
    "\n",
    "#seed = 1234\n",
    "#random.seed(seed)\n",
    "#torch.manual_seed(seed)\n",
    "#torch.cuda.manual_seed_all(seed)\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = r'D:\\MachineLearning\\Models\\phamquiluan-PubLayNet\\model_196000.pth'\n",
    "num_classes = 6\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "#model.cuda()\n",
    "\n",
    "assert os.path.exists(checkpoint_path)\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask(image, mask, alpha=0.5):\n",
    "    c = (np.random.random((1, 3)) * 153 + 102).tolist()[0]\n",
    " \n",
    "    mask = np.dstack([mask.astype(np.uint8)] * 3)\n",
    "    mask = cv2.threshold(mask, 127.5, 255, cv2.THRESH_BINARY)[1]\n",
    "    inv_mask = 255 - mask\n",
    "\n",
    "    overlay = image.copy()\n",
    "    overlay = np.minimum(overlay, inv_mask) \n",
    "\n",
    "    color_mask = (mask.astype(np.bool) * c).astype(np.uint8)\n",
    "    overlay = np.maximum(overlay, color_mask).astype(np.uint8) \n",
    "\n",
    "    image = cv2.addWeighted(image, alpha, overlay, 1 - alpha, 0)\n",
    "    return image\n",
    "\n",
    "def overlay_ann(image, mask, box, label, score, alpha=0.5):\n",
    "    c = np.random.random((1, 3))\n",
    "    mask_color = (c * 153 + 102).tolist()[0]\n",
    "    text_color = (c * 183 + 72).tolist()[0]\n",
    " \n",
    "    mask = np.dstack([mask.astype(np.uint8)] * 3)\n",
    "    mask = cv2.threshold(mask, 127.5, 255, cv2.THRESH_BINARY)[1]\n",
    "    inv_mask = 255 - mask\n",
    "\n",
    "    overlay = image.copy()\n",
    "    overlay = np.minimum(overlay, inv_mask) \n",
    "\n",
    "    color_mask = (mask.astype(np.bool) * mask_color).astype(np.uint8)\n",
    "        \n",
    "    overlay = np.maximum(overlay, color_mask).astype(np.uint8) \n",
    "\n",
    "    image = cv2.addWeighted(image, alpha, overlay, 1 - alpha, 0)\n",
    "\n",
    "    # draw on color mask\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (box[0], box[1]),\n",
    "        (box[2], box[3]),\n",
    "        mask_color, 1\n",
    "    )\n",
    "\n",
    "    (label_size_width, label_size_height), base_line = \\\n",
    "        cv2.getTextSize(\n",
    "            \"{}\".format(label),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.3, 1\n",
    "        )\n",
    "\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (box[0], box[1] + 10),\n",
    "        (box[0] + label_size_width, box[1] + 10 - label_size_height),\n",
    "        (223, 128, 255),\n",
    "        cv2.FILLED\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        # \"{}: {:.3f}\".format(label, score),\n",
    "        \"{}\".format(label),\n",
    "        (box[0], box[1] + 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.3, (0, 0, 0), 1\n",
    "    )\n",
    " \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit\n",
    "image_path = r'D:\\Datasets\\Document Layout Analysis\\PubLayNet\\PMC5055614_00000.jpg'\n",
    "assert os.path.exists(image_path)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "#print(image)\n",
    "\n",
    "rat = 1300 / image.shape[0]\n",
    "image = cv2.resize(image, None, fx=rat, fy=rat)\n",
    "#print(image)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image = transform(image)\n",
    "#print('image=' + str(image[1][200]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model([image]) #.cuda()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.squeeze(image, 0).permute(1, 2, 0).mul(255).numpy().astype(np.uint8)\n",
    "#print(image)\n",
    "\n",
    "print('prediction=' + str(len(prediction)))\n",
    "\n",
    "for pred in prediction:\n",
    "    print('mask=' + str(pred['masks'].shape))\n",
    "    print('boxes=' + str(pred['boxes'].shape))\n",
    "    print('labels=' + str(pred['labels'].shape))\n",
    "    print('scores=' + str(pred['scores'].shape))\n",
    "    for idx, mask in enumerate(pred['masks']):\n",
    "        if pred['scores'][idx].item() < 0.7:\n",
    "            continue\n",
    "\n",
    "        m = mask[0].mul(255).byte().cpu().numpy()\n",
    "        box = list(map(int, pred[\"boxes\"][idx].tolist()))\n",
    "        label = CATEGORIES2LABELS[pred[\"labels\"][idx].item()]\n",
    "\n",
    "        score = pred[\"scores\"][idx].item()\n",
    "\n",
    "        #image = overlay_mask(image, m)\n",
    "        image = overlay_ann(image, m, box, label, score)\n",
    "\n",
    "cv2.imwrite('test.jpg', image)\n",
    "#show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mask=' + str(prediction[0]['masks'].shape))\n",
    "print('boxes=\\n' + str(prediction[0]['boxes']))\n",
    "print('labels=\\n' + str(prediction[0]['labels']))\n",
    "print('scores=\\n' + str(prediction[0]['scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(3, 1300, 1300, requires_grad=True)\n",
    "\n",
    "#image = cv2.imread(image_path)\n",
    "#rat = 1300 / image.shape[0]\n",
    "#rat2 = 1300 / image.shape[1] \n",
    "#image = cv2.resize(image, None, fx=rat2, fy=rat)\n",
    "#print(image.shape)\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.ToPILImage(),\n",
    "#    transforms.ToTensor()\n",
    "#])\n",
    "#image = transform(image)\n",
    "\n",
    "torch.onnx.export(model, [image], 'model_196000.1.onnx', opset_version=12,\n",
    "                  input_names = ['image'],\n",
    "                  output_names = ['boxes', 'labels', 'scores', 'masks'],\n",
    "                  dynamic_axes=\n",
    "                  { \n",
    "                      'masks' : {0 : 'pred'},\n",
    "                      'boxes' : {0 : 'pred'},\n",
    "                      'labels' : {0 : 'pred'},\n",
    "                      'scores' : {0 : 'pred'},\n",
    "                  })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert mask-rcnn Torch model to ONNX\n",
    "\n",
    "Most of the code is taken from https://github.com/phamquiluan/PubLayNet/blob/master/maskrcnn/infer.py\n",
    "\n",
    "TODO - optimise model:\n",
    "- https://github.com/microsoft/onnxruntime/issues/1899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.transforms import transforms\n",
    "from onnx import optimizer\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoint from https://github.com/phamquiluan/PubLayNet\n",
    "checkpoint_path = r'D:\\MachineLearning\\Models\\phamquiluan-PubLayNet\\model_196000.pth'\n",
    "num_classes = 6\n",
    "CATEGORIES2LABELS = { 0: \"bg\", 1: \"text\", 2: \"title\", 3: \"list\", 4: \"table\", 5: \"figure\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "    model.training = False\n",
    "    return model\n",
    "\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_instance_segmentation_model(num_classes)\n",
    "\n",
    "assert os.path.exists(checkpoint_path)\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(3, 1300, 1300, requires_grad=True)\n",
    "torch.onnx.export(model, [image], \n",
    "                  'model_196000_v12.onnx', \n",
    "                  opset_version=12,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names = ['image'],\n",
    "                  output_names = ['boxes', 'labels', 'scores', 'masks'],\n",
    "                  dynamic_axes=\n",
    "                  {\n",
    "                      'masks' : {0 : 'pred'},\n",
    "                      'boxes' : {0 : 'pred'},\n",
    "                      'labels' : {0 : 'pred'},\n",
    "                      'scores' : {0 : 'pred'},\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_path = 'model_196000_before_opt.onnx'\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.roi_heads.box_predictor.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in model.roi_heads.mask_predictor.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    image = torch.randn(3, 1300, 1300, requires_grad=False)\n",
    "    torch.onnx.export(model,\n",
    "                      [image], \n",
    "                      model_path, \n",
    "                      opset_version=11,\n",
    "                      do_constant_folding=True,\n",
    "                      input_names = ['image'],\n",
    "                      output_names = ['boxes', 'labels', 'scores', 'masks'],\n",
    "                      dynamic_axes=\n",
    "                      {\n",
    "                          'masks' : {0 : 'nbox'},\n",
    "                          'boxes' : {0 : 'nbox'},\n",
    "                          'labels' : {0 : 'nbox'},\n",
    "                          'scores' : {0 : 'nbox'},\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/BowenBao/maskrcnn-benchmark/blob/onnx_stage/demo/export_to_onnx.py\n",
    "#postprocess_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/microsoft/onnxruntime/blob/master/tools/python/remove_initializer_from_input.py\n",
    "model_path = 'model_196000_opt.onnx'\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "inputs = model.graph.input\n",
    "name_to_input = {}\n",
    "for input in inputs:\n",
    "    name_to_input[input.name] = input\n",
    "\n",
    "for initializer in model.graph.initializer:\n",
    "    if initializer.name in name_to_input:\n",
    "        inputs.remove(name_to_input[initializer.name])\n",
    "\n",
    "onnx.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value_info_for_constants(model : onnx.ModelProto):\n",
    "    \"\"\"\n",
    "    Currently onnx.shape_inference doesn't use the shape of initializers, so add\n",
    "    that info explicitly as ValueInfoProtos.\n",
    "    Mutates the model.\n",
    "    Args:\n",
    "        model: The ModelProto to update.\n",
    "    \"\"\"\n",
    "    # All (top-level) constants will have ValueInfos before IRv4 as they are all inputs\n",
    "    if model.ir_version < 4:\n",
    "        return\n",
    "\n",
    "    def add_const_value_infos_to_graph(graph : onnx.GraphProto):\n",
    "        inputs = {i.name for i in graph.input}\n",
    "        existing_info = {vi.name: vi for vi in graph.value_info}\n",
    "        for init in graph.initializer:\n",
    "            # Check it really is a constant, not an input\n",
    "            if init.name in inputs:\n",
    "                continue\n",
    "\n",
    "            # The details we want to add\n",
    "            elem_type = init.data_type\n",
    "            shape = init.dims\n",
    "\n",
    "            # Get existing or create new value info for this constant\n",
    "            vi = existing_info.get(init.name)\n",
    "            if vi is None:\n",
    "                vi = graph.value_info.add()\n",
    "                vi.name = init.name\n",
    "\n",
    "            # Even though it would be weird, we will not overwrite info even if it doesn't match\n",
    "            tt = vi.type.tensor_type\n",
    "            if tt.elem_type == onnx.TensorProto.UNDEFINED:\n",
    "                tt.elem_type = elem_type\n",
    "            if not tt.HasField(\"shape\"):\n",
    "                # Ensure we set an empty list if the const is scalar (zero dims)\n",
    "                tt.shape.dim.extend([])\n",
    "                for dim in shape:\n",
    "                    tt.shape.dim.add().dim_value = dim\n",
    "\n",
    "        # Handle subgraphs\n",
    "        for node in graph.node:\n",
    "            for attr in node.attribute:\n",
    "                # Ref attrs refer to other attrs, so we don't need to do anything\n",
    "                if attr.ref_attr_name != \"\":\n",
    "                    continue\n",
    "\n",
    "                if attr.type == onnx.AttributeProto.GRAPH:\n",
    "                    add_const_value_infos_to_graph(attr.g)\n",
    "                if attr.type == onnx.AttributeProto.GRAPHS:\n",
    "                    for g in attr.graphs:\n",
    "                        add_const_value_infos_to_graph(g)\n",
    "\n",
    "\n",
    "    return add_const_value_infos_to_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_196000_before_opt.onnx'\n",
    "onnx_model = onnx.load(model_path)\n",
    "passes = [\"extract_constant_to_initializer\", \"eliminate_unused_initializer\"]\n",
    "\n",
    "onnx_model = optimizer.optimize(onnx_model)#, passes)\n",
    "onnx.save(onnx_model, 'model_196000_after_opt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/microsoft/onnxruntime/issues/1899\n",
    "# https://github.com/onnx/onnx/issues/2903\n",
    "# https://github.com/microsoft/onnxruntime/issues/4033\n",
    "\n",
    "model_path = 'model_196000_before_opt.onnx'\n",
    "\n",
    "onnx_model = onnx.load(model_path)\n",
    "add_value_info_for_constants(onnx_model)\n",
    "onnx_model = onnx.shape_inference.infer_shapes(onnx_model)\n",
    "\n",
    "for init in onnx_model.graph.initializer:\n",
    "    for value_info in onnx_model.graph.value_info:\n",
    "        if init.name == value_info.name:\n",
    "            onnx_model.graph.input.append(value_info)\n",
    "            \n",
    "# Handle subgraphs\n",
    "for node in onnx_model.graph.node:\n",
    "    for attr in node.attribute:\n",
    "        # Ref attrs refer to other attrs, so we don't need to do anything\n",
    "        if attr.ref_attr_name != \"\":\n",
    "            continue\n",
    "\n",
    "        if attr.type == onnx.AttributeProto.GRAPH:\n",
    "            for initializer in attr.g.initializer:\n",
    "                for value_info in attr.g.value_info:\n",
    "                    if init.name == value_info.name:\n",
    "                        attr.g.input.append(value_info)\n",
    "            \n",
    "        if attr.type == onnx.AttributeProto.GRAPHS:\n",
    "            for g in attr.graphs:\n",
    "                for init in g.initializer:\n",
    "                    for value_info in g.value_info:\n",
    "                        if init.name == value_info.name:\n",
    "                            g.input.append(value_info)\n",
    "                        \n",
    "\n",
    "passes = [\"extract_constant_to_initializer\", \"eliminate_unused_initializer\"]\n",
    "\n",
    "onnx_model = optimizer.optimize(onnx_model)#, passes)\n",
    "\n",
    "inputs = onnx_model.graph.input\n",
    "name_to_input = {}\n",
    "for input in inputs:\n",
    "    name_to_input[input.name] = input\n",
    "\n",
    "for initializer in onnx_model.graph.initializer:\n",
    "    if initializer.name in name_to_input:\n",
    "        inputs.remove(name_to_input[initializer.name])\n",
    "\n",
    "# Handle subgraphs\n",
    "for node in onnx_model.graph.node:\n",
    "    for attr in node.attribute:\n",
    "        # Ref attrs refer to other attrs, so we don't need to do anything\n",
    "        if attr.ref_attr_name != \"\":\n",
    "            continue\n",
    "\n",
    "        if attr.type == onnx.AttributeProto.GRAPH:\n",
    "            inputs = attr.g.input\n",
    "            name_to_input = {}\n",
    "            for input in inputs:\n",
    "                name_to_input[input.name] = input\n",
    "\n",
    "            for initializer in attr.g.initializer:\n",
    "                if initializer.name in name_to_input:\n",
    "                    inputs.remove(name_to_input[initializer.name])\n",
    "        \n",
    "        if attr.type == onnx.AttributeProto.GRAPHS:\n",
    "            for g in attr.graphs:\n",
    "                inputs = g.input\n",
    "                name_to_input = {}\n",
    "                for input in inputs:\n",
    "                    name_to_input[input.name] = input\n",
    "\n",
    "                for initializer in g.initializer:\n",
    "                    if initializer.name in name_to_input:\n",
    "                        inputs.remove(name_to_input[initializer.name])\n",
    "                        \n",
    "onnx.save(onnx_model, 'model_196000_after_opt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unused_floor(model):\n",
    "    nodes = model.graph.node\n",
    "\n",
    "    for i, n in enumerate(nodes):\n",
    "        n.name = str(i)\n",
    "\n",
    "    floor_nodes = [node for node in nodes if node.op_type=='Floor']\n",
    "\n",
    "    for f in floor_nodes:\n",
    "        in_id = f.input[0]\n",
    "        out_id = f.output[0]\n",
    "        in_n = [node for node in nodes if node.output == [in_id]][0]\n",
    "        if in_n.op_type == 'Mul':\n",
    "            out_n = [node for node in nodes if node.input == [out_id]][0]\n",
    "            out_n.input[0] = in_n.output[0]\n",
    "            nodes.remove(f)\n",
    "            print(f)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
